```markdown
# Financial Data Pipeline (Python + PostgreSQL)

This project demonstrates a production-style financial data pipeline built with Python and PostgreSQL.

It incrementally fetches market data via API, cleans and stores it in a relational database, computes analytical metrics, and visualizes results. The system is modular, configurable via CLI, and designed to reflect real-world data engineering and automation practices.

---

## ğŸš€ Key Capabilities

- Incremental data ingestion (only new records are fetched)
- API integration (yfinance)
- Data cleaning and validation
- Persistent storage in PostgreSQL
- Analytical metrics:
  - Moving averages (MA20, MA50)
  - Volatility
  - Min/Max price
- Visualization with Matplotlib/Seaborn
- CLI-driven execution (ticker and date overrides)
- Modular architecture
- Logging for operational monitoring
- Interactive exploration via Jupyter Notebook

---

## ğŸ— Architecture Overview

The pipeline follows this flow:

API â†’ Raw Data â†’ Cleaning â†’ PostgreSQL Storage â†’ Analytics â†’ Visualization

Key characteristics:

- Incremental updates based on latest DB date
- Separation of concerns (fetching, cleaning, DB, analytics, visualization)
- Configuration management via `config.py`
- CLI overrides for flexible execution
- Structured logging

---

## ğŸ“‚ Repository Structure

```

data_pipeline_project/
â”œâ”€ assets/
â”‚   â””â”€ plot_example.png
â”œâ”€ config.py
â”œâ”€ main.py
â”œâ”€ modules/
â”‚   â”œâ”€ data_fetcher.py
â”‚   â”œâ”€ data_cleaner.py
â”‚   â”œâ”€ database.py
â”‚   â”œâ”€ analytics.py
â”‚   â”œâ”€ analyzer.py
â”‚   â””â”€ visualizer.py
â”œâ”€ notebooks/
â”‚   â””â”€ exploration.ipynb
â”œâ”€ requirements.txt
â””â”€ README.md

````

---

## âš™ Installation

```bash
git clone https://github.com/<your-username>/<repo>.git
cd data_pipeline_project
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
````

---

## ğŸ”§ Configuration

Edit `config.py`:

```python
TICKER = "AAPL"
START_DATE = "2022-01-01"

DB_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "database": "stocks",
    "user": "your_user",
    "password": "your_password"
}
```

CLI arguments override config values.

---

## â–¶ Usage

### Default execution (uses config values)

```bash
python main.py
```

### Specify ticker

```bash
python main.py --ticker MSFT
```

### Specify full date range

```bash
python main.py --ticker NVDA --start 2023-01-01 --end 2023-12-31
```

If no start date is provided, the pipeline automatically detects the latest stored date in PostgreSQL and fetches only missing data.

---

## ğŸ—„ Example SQL Query

Once data is stored in PostgreSQL, it can be queried directly:

```sql
SELECT date, open, close
FROM analytics.stock_prices
WHERE ticker = 'AAPL'
ORDER BY date DESC
LIMIT 10;
```

---

## ğŸ“Š Example Output (Console Summary)

```
Mean_price: 103.165304
Volatility: 0.03128
Max_price: 207.028473
Min_price: 14.250734
```

---

## ğŸ“ˆ Example Visualization

Close price with MA20 and MA50:

![Example Plot](assets/plot_example.png)

---

## ğŸ§ª Interactive Exploration

Open:

```
notebooks/exploration.ipynb
```

This notebook allows:

* manual experimentation
* additional metrics
* correlation checks
* exploratory analysis

---

## ğŸ›  Technologies

* Python 3.9+
* Pandas, NumPy
* PostgreSQL
* SQLAlchemy, psycopg2
* Matplotlib, Seaborn
* yfinance API
* argparse (CLI)
* logging

---

## ğŸ¯ Purpose

This project was built to demonstrate:

* End-to-end data pipeline design
* Automation mindset
* Modular Python architecture
* Practical SQL integration
* Real-world analytics workflow

---

## License

MIT License

```

---